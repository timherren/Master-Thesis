services:
  app:
    build: .
    ports:
      - "8000:8000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      LLM_PROVIDER: ollama
      OLLAMA_BASE_URL: http://host.docker.internal:11434/v1
      OLLAMA_API_KEY: ollama
      LLM_MODEL_DECISION: llama3.2:1b
      LLM_MODEL_INTERPRETATION: llama3.2:latest
      # R DAG wrapper uses these names (separate from Python client env vars)
      OLLAMA_HOST: http://host.docker.internal:11434
      OLLAMA_DAG_MODEL: llama3.2:latest
    volumes:
      - ./app/runtime:/app/app/runtime
